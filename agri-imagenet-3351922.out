[rank: 0] Seed set to 0
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/projects/bcnh/spack/var/spack/environments/dali/.spack-env/view/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default
You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
Missing logger folder: /u/ychang3/torchgeo/lightning_logs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name          | Type             | Params
---------------------------------------------------
0 | model         | Unet             | 14.4 M
1 | criterion     | CrossEntropyLoss | 0     
2 | train_metrics | MetricCollection | 0     
3 | val_metrics   | MetricCollection | 0     
4 | test_metrics  | MetricCollection | 0     
---------------------------------------------------
14.4 M    Trainable params
0         Non-trainable params
14.4 M    Total params
57.433    Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:24<00:24,  0.04it/s]Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:24<00:00,  0.08it/s]                                                                           Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/324 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/324 [00:00<?, ?it/s] Epoch 0:   0%|          | 1/324 [1:32:36<498:33:21,  0.00it/s]Epoch 0:   0%|          | 1/324 [1:32:36<498:34:26,  0.00it/s, v_num=0]Epoch 0:   1%|          | 2/324 [1:32:37<248:31:37,  0.00it/s, v_num=0]Epoch 0:   1%|          | 2/324 [1:32:37<248:31:37,  0.00it/s, v_num=0]Epoch 0:   1%|          | 3/324 [1:32:37<165:10:52,  0.00it/s, v_num=0]Epoch 0:   1%|          | 3/324 [1:32:37<165:10:52,  0.00it/s, v_num=0]Epoch 0:   1%|          | 4/324 [1:32:37<123:30:28,  0.00it/s, v_num=0]Epoch 0:   1%|          | 4/324 [1:32:37<123:30:28,  0.00it/s, v_num=0]Epoch 0:   2%|▏         | 5/324 [1:32:38<98:30:14,  0.00it/s, v_num=0] Epoch 0:   2%|▏         | 5/324 [1:32:38<98:30:14,  0.00it/s, v_num=0]Epoch 0:   2%|▏         | 6/324 [1:32:38<81:50:04,  0.00it/s, v_num=0]Epoch 0:   2%|▏         | 6/324 [1:32:38<81:50:04,  0.00it/s, v_num=0]Epoch 0:   2%|▏         | 7/324 [1:32:38<69:55:40,  0.00it/s, v_num=0]Epoch 0:   2%|▏         | 7/324 [1:32:38<69:55:40,  0.00it/s, v_num=0]Epoch 0:   2%|▏         | 8/324 [1:32:39<60:59:51,  0.00it/s, v_num=0]Epoch 0:   2%|▏         | 8/324 [1:32:39<60:59:51,  0.00it/s, v_num=0]Epoch 0:   3%|▎         | 9/324 [3:08:59<110:14:59,  0.00it/s, v_num=0]Epoch 0:   3%|▎         | 9/324 [3:09:00<110:15:07,  0.00it/s, v_num=0]Epoch 0:   3%|▎         | 10/324 [3:09:00<98:54:51,  0.00it/s, v_num=0]Epoch 0:   3%|▎         | 10/324 [3:09:00<98:54:51,  0.00it/s, v_num=0]Epoch 0:   3%|▎         | 11/324 [3:09:00<89:38:19,  0.00it/s, v_num=0]Epoch 0:   3%|▎         | 11/324 [3:09:00<89:38:19,  0.00it/s, v_num=0]Epoch 0:   4%|▎         | 12/324 [3:09:01<81:54:32,  0.00it/s, v_num=0]Epoch 0:   4%|▎         | 12/324 [3:09:01<81:54:32,  0.00it/s, v_num=0]Epoch 0:   4%|▍         | 13/324 [3:09:01<75:22:06,  0.00it/s, v_num=0]Epoch 0:   4%|▍         | 13/324 [3:09:01<75:22:06,  0.00it/s, v_num=0]Epoch 0:   4%|▍         | 14/324 [3:09:01<69:45:43,  0.00it/s, v_num=0]Epoch 0:   4%|▍         | 14/324 [3:09:01<69:45:43,  0.00it/s, v_num=0]Epoch 0:   5%|▍         | 15/324 [3:09:02<64:54:12,  0.00it/s, v_num=0]Epoch 0:   5%|▍         | 15/324 [3:09:02<64:54:12,  0.00it/s, v_num=0]Epoch 0:   5%|▍         | 16/324 [3:09:02<60:39:06,  0.00it/s, v_num=0]Epoch 0:   5%|▍         | 16/324 [3:09:02<60:39:06,  0.00it/s, v_num=0]Epoch 0:   5%|▌         | 17/324 [4:30:12<81:19:29,  0.00it/s, v_num=0]Epoch 0:   5%|▌         | 17/324 [4:30:12<81:19:33,  0.00it/s, v_num=0]Epoch 0:   6%|▌         | 18/324 [4:30:12<76:33:32,  0.00it/s, v_num=0]Epoch 0:   6%|▌         | 18/324 [4:30:12<76:33:32,  0.00it/s, v_num=0]Epoch 0:   6%|▌         | 19/324 [4:30:12<72:17:39,  0.00it/s, v_num=0]Epoch 0:   6%|▌         | 19/324 [4:30:12<72:17:39,  0.00it/s, v_num=0]Epoch 0:   6%|▌         | 20/324 [4:30:13<68:27:20,  0.00it/s, v_num=0]Epoch 0:   6%|▌         | 20/324 [4:30:13<68:27:20,  0.00it/s, v_num=0]Epoch 0:   6%|▋         | 21/324 [4:30:13<64:58:58,  0.00it/s, v_num=0]Epoch 0:   6%|▋         | 21/324 [4:30:13<64:58:58,  0.00it/s, v_num=0]Epoch 0:   7%|▋         | 22/324 [4:30:13<61:49:33,  0.00it/s, v_num=0]Epoch 0:   7%|▋         | 22/324 [4:30:13<61:49:33,  0.00it/s, v_num=0]Epoch 0:   7%|▋         | 23/324 [4:30:14<58:56:35,  0.00it/s, v_num=0]Epoch 0:   7%|▋         | 23/324 [4:30:14<58:56:35,  0.00it/s, v_num=0]Epoch 0:   7%|▋         | 24/324 [4:30:14<56:18:03,  0.00it/s, v_num=0]Epoch 0:   7%|▋         | 24/324 [4:30:14<56:18:03,  0.00it/s, v_num=0]Epoch 0:   8%|▊         | 25/324 [7:49:02<93:29:46,  0.00it/s, v_num=0]Epoch 0:   8%|▊         | 25/324 [7:49:02<93:29:47,  0.00it/s, v_num=0]Epoch 0:   8%|▊         | 26/324 [7:49:03<89:36:03,  0.00it/s, v_num=0]Epoch 0:   8%|▊         | 26/324 [7:49:03<89:36:03,  0.00it/s, v_num=0]Epoch 0:   8%|▊         | 27/324 [7:49:03<85:59:38,  0.00it/s, v_num=0]Epoch 0:   8%|▊         | 27/324 [7:49:03<85:59:38,  0.00it/s, v_num=0]Epoch 0:   9%|▊         | 28/324 [7:52:07<83:11:02,  0.00it/s, v_num=0]Epoch 0:   9%|▊         | 28/324 [7:52:07<83:11:02,  0.00it/s, v_num=0]Epoch 0:   9%|▉         | 29/324 [7:52:07<80:02:43,  0.00it/s, v_num=0]Epoch 0:   9%|▉         | 29/324 [7:52:07<80:02:43,  0.00it/s, v_num=0]Epoch 0:   9%|▉         | 30/324 [7:52:08<77:06:56,  0.00it/s, v_num=0]Epoch 0:   9%|▉         | 30/324 [7:52:08<77:06:56,  0.00it/s, v_num=0]Epoch 0:  10%|▉         | 31/324 [7:52:08<74:22:31,  0.00it/s, v_num=0]Epoch 0:  10%|▉         | 31/324 [7:52:08<74:22:31,  0.00it/s, v_num=0]Epoch 0:  10%|▉         | 32/324 [7:52:08<71:48:21,  0.00it/s, v_num=0]Epoch 0:  10%|▉         | 32/324 [7:52:08<71:48:21,  0.00it/s, v_num=0]slurmstepd: error: *** JOB 3351922 ON gpua035 CANCELLED AT 2024-04-04T02:46:58 ***
