# Copyright (c) TorchGeo Contributors. All rights reserved.
# Licensed under the MIT License.

"""South Africa Crop Type Competition Dataset."""

import os
import re
from collections.abc import Callable, Iterable, Sequence
from typing import ClassVar

import matplotlib.pyplot as plt
import pandas as pd
import rasterio
import torch
from matplotlib.figure import Figure
from pyproj import CRS
from torch import Tensor

from .errors import DatasetNotFoundError, RGBBandsMissingError
from .geo import RasterDataset
from .utils import GeoSlice, Path, Sample, which


class SouthAfricaCropType(RasterDataset):
    """South Africa Crop Type Challenge dataset.

    The `South Africa Crop Type Challenge
    <https://beta.source.coop/repositories/radiantearth/south-africa-crops-competition/description/>`__
    dataset includes satellite imagery from Sentinel-1 and Sentinel-2 and labels for
    crop type that were collected by aerial and vehicle survey from May 2017 to March
    2018. Data was provided by the Western Cape Department of Agriculture and is
    available via the Radiant Earth Foundation. For each field id the dataset contains
    time series imagery and a single label mask. Note that the dates for S1 and S2
    imagery for a given field are not guaranteed to be the same. Due to this date
    mismatch only S1 or S2 bands may be queried at a time, a mix of both is not
    supported. Each pixel in the label contains an integer field number and crop type
    class.

    Dataset format:

    * images are time-series 2-band Sentinel 1 and 12-band Sentinel-2 data
      returned as T x C x H x W tensors, where T is the number of timesteps
    * masks are tiff images with unique values representing the class and field id.

    Dataset classes:

    0. No Data
    1. Lucerne/Medics
    2. Planted pastures (perennial)
    3. Fallow
    4. Wine grapes
    5. Weeds
    6. Small grain grazing
    7. Wheat
    8. Canola
    9. Rooibos

    If you use this dataset in your research, please cite the following dataset:

    * Western Cape Department of Agriculture, Radiant Earth Foundation (2021)
      "Crop Type Classification Dataset for Western Cape, South Africa",
      Version 1.0, Radiant MLHub, https://doi.org/10.34911/rdnt.j0co8q

    .. note::
       This dataset requires the following additional library to be installed:

       * `azcopy <https://github.com/Azure/azure-storage-azcopy>`_: to download the
         dataset from Source Cooperative.

    .. versionadded:: 0.6
    """

    url = 'https://radiantearth.blob.core.windows.net/mlhub/ref-south-africa-crops-competition-v1'

    filename_glob = '*_{}_10m.*'
    filename_regex = r"""
        ^(?P<field_id>\d+)
        _(?P<date>\d{4}_\d{2}_\d{2})
        _(?P<band>[BHV\d]+)
        _10m
    """
    date_format = '%Y_%m_%d'
    rgb_bands = ('B04', 'B03', 'B02')
    s1_bands = ('VH', 'VV')
    s2_bands = (
        'B01',
        'B02',
        'B03',
        'B04',
        'B05',
        'B06',
        'B07',
        'B08',
        'B8A',
        'B09',
        'B11',
        'B12',
    )
    all_bands = s1_bands + s2_bands
    cmap: ClassVar[dict[int, tuple[int, int, int, int]]] = {
        0: (0, 0, 0, 255),
        1: (255, 211, 0, 255),
        2: (255, 37, 37, 255),
        3: (0, 168, 226, 255),
        4: (255, 158, 9, 255),
        5: (37, 111, 0, 255),
        6: (255, 255, 0, 255),
        7: (222, 166, 9, 255),
        8: (111, 166, 0, 255),
        9: (0, 175, 73, 255),
    }

    def __init__(
        self,
        paths: Path | Iterable[Path] = 'data',
        crs: CRS | None = None,
        classes: Sequence[int] = list(cmap.keys()),
        bands: Sequence[str] = s2_bands,
        transforms: Callable[[Sample], Sample] | None = None,
        download: bool = False,
    ) -> None:
        """Initialize a new South Africa Crop Type dataset instance.

        Args:
            paths: paths directory where dataset can be found
            crs: coordinate reference system to be used
            classes: crop type classes to be included
            bands: the subset of bands to load
            transforms: a function/transform that takes input sample and its target as
                entry and returns a transformed version
            download: if True, download dataset and store it in the root directory

        Raises:
            DatasetNotFoundError: If dataset is not found and *download* is False.
        """
        assert set(classes) <= self.cmap.keys(), (
            f'Only the following classes are valid: {list(self.cmap.keys())}.'
        )
        assert 0 in classes, 'Classes must include the background class: 0'

        self.paths = paths
        self.download = download
        self.filename_glob = self.filename_glob.format(bands[0])

        self._verify()

        super().__init__(paths=paths, crs=crs, bands=bands, transforms=transforms)

        # Map chosen classes to ordinal numbers, all others mapped to background class
        self.ordinal_map = torch.zeros(max(self.cmap.keys()) + 1, dtype=self.dtype)
        self.ordinal_cmap = torch.zeros((len(classes), 4), dtype=torch.uint8)
        for v, k in enumerate(classes):
            self.ordinal_map[k] = v
            self.ordinal_cmap[v] = torch.tensor(self.cmap[k])

    def __getitem__(self, index: GeoSlice) -> Sample:
        """Retrieve input, target, and/or metadata indexed by spatiotemporal slice.

        Args:
            index: [xmin:xmax:xres, ymin:ymax:yres, tmin:tmax:tres] coordinates to index.

        Returns:
            Sample of input, target, and/or metadata at that index.

        Raises:
            IndexError: If *index* is not found in the dataset.
        """
        x, y, t = self._disambiguate_slice(index)
        interval = pd.Interval(t.start, t.stop)
        df = self.index.iloc[self.index.index.overlaps(interval)]
        df = df.iloc[:: t.step]
        df = df.cx[x.start : x.stop, y.start : y.stop]

        if df.empty:
            raise IndexError(
                f'index: {index} not found in dataset with bounds: {self.bounds}'
            )

        filename_regex = re.compile(self.filename_regex, re.VERBOSE)

        # Loop through matched filepaths and find all unique field ids and dates
        field_ids: list[str] = []
        imagery_dates: dict[str, dict[str, set[str]]] = {}

        for filepath in df.filepath:
            filename = os.path.basename(filepath)
            match = re.match(filename_regex, filename)
            if match:
                field_id = match.group('field_id')
                date = match.group('date')
                band = match.group('band')
                band_type = 's1' if band in self.s1_bands else 's2'
                if field_id not in field_ids:
                    field_ids.append(field_id)
                    imagery_dates[field_id] = {'s1': set(), 's2': set()}
                imagery_dates[field_id][band_type].add(date)

        # Determine band type and collect sorted unique dates across all fields
        band_type = 's1' if self.bands[0] in self.s1_bands else 's2'
        all_dates: set[str] = set()
        for field_id in field_ids:
            all_dates |= imagery_dates[field_id][band_type]
        sorted_dates = sorted(all_dates)

        # Create T x C x H x W tensor
        assert isinstance(self.paths, str | os.PathLike)
        timesteps: list[Tensor] = []
        for date in sorted_dates:
            band_list: list[Tensor] = []
            for band in self.bands:
                band_filepaths = []
                for field_id in field_ids:
                    filepath = os.path.join(
                        self.paths,
                        'train',
                        'imagery',
                        band_type,
                        field_id,
                        date,
                        f'{field_id}_{date}_{band}_10m.tif',
                    )
                    band_filepaths.append(filepath)
                band_list.append(self._merge_files(band_filepaths, index))
            timesteps.append(torch.cat(band_list))
        image = torch.stack(timesteps)

        # Add labels for each field
        mask_filepaths: list[str] = []
        for field_id in field_ids:
            file_path = filepath = os.path.join(
                self.paths, 'train', 'labels', f'{field_id}.tif'
            )
            mask_filepaths.append(file_path)

        mask = self._merge_files(mask_filepaths, index).squeeze(0)

        transform = rasterio.transform.from_origin(x.start, y.stop, x.step, y.step)
        sample = {
            'bounds': self._slice_to_tensor(index),
            'image': image.float(),
            'mask': mask.long(),
            'transform': torch.tensor(transform),
        }

        if self.transforms is not None:
            sample = self.transforms(sample)

        return sample

    def _verify(self) -> None:
        """Verify the integrity of the dataset."""
        # Check if the files already exist
        if self.files:
            return

        # Check if the user requested to download the dataset
        if not self.download:
            raise DatasetNotFoundError(self)

        # Download the dataset
        self._download()

    def _download(self) -> None:
        """Download the dataset."""
        assert isinstance(self.paths, str | os.PathLike)
        os.makedirs(self.paths, exist_ok=True)
        azcopy = which('azcopy')
        azcopy('sync', f'{self.url}', self.paths, '--recursive=true')

    def plot(
        self, sample: Sample, show_titles: bool = True, suptitle: str | None = None
    ) -> Figure:
        """Plot a sample from the dataset.

        Args:
            sample: a sample returned by :meth:`__getitem__`
            show_titles: flag indicating whether to show titles above each panel
            suptitle: optional string to use as a suptitle

        Returns:
            a matplotlib Figure with the rendered sample

        Raises:
            RGBBandsMissingError: If *bands* does not include all RGB bands.
        """
        rgb_indices = []
        for band in self.rgb_bands:
            if band in self.bands:
                rgb_indices.append(self.bands.index(band))
            else:
                raise RGBBandsMissingError()

        images = sample['image'][:, rgb_indices].numpy().transpose(0, 2, 3, 1)
        images = (images - images.min()) / (images.max() - images.min())

        mask = sample['mask'].squeeze()
        num_timesteps = images.shape[0]
        ncols = num_timesteps + 1

        if 'prediction' in sample:
            ncols += 1

        fig, axs = plt.subplots(
            nrows=1, ncols=ncols, figsize=(ncols * 4, 4), squeeze=False
        )

        for t in range(num_timesteps):
            axs[0, t].imshow(images[t])
            axs[0, t].axis('off')
            if show_titles:
                axs[0, t].set_title(f'Image {t}')

        axs[0, num_timesteps].imshow(self.ordinal_cmap[mask], interpolation='none')
        axs[0, num_timesteps].axis('off')
        if show_titles:
            axs[0, num_timesteps].set_title('Mask')

        if 'prediction' in sample:
            axs[0, num_timesteps + 1].imshow(sample['prediction'].squeeze())
            axs[0, num_timesteps + 1].axis('off')
            if show_titles:
                axs[0, num_timesteps + 1].set_title('Prediction')

        if suptitle is not None:
            plt.suptitle(suptitle)

        return fig
